services:
# TODO: hadoop fs -mkdir -p /user/spark/input -> IMPORTANT COMMAND
    namenode:
        build:
            context: ./hadoop/namenode
            dockerfile: Dockerfile
        image: ionicastefan20/hadoop-namenode:3.3.6
        container_name: namenode
        hostname: namenode
        environment:
            - CLUSTER_NAME=test
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
            - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
        ports:
            - 9870:9870
            - 9000:9000
        volumes:
            - hadoop-namenode:/hadoop/dfs/name
            - ./data/hadoop:/mnt/data

    datanode:
        build:
            context: ./hadoop/datanode
            dockerfile: Dockerfile
        image: ionicastefan20/hadoop-datanode:3.3.6
        container_name: datanode
        hostname: datanode
        depends_on:
            - namenode
        environment:
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
            - HDFS_CONF_dfs_datanode_data_dir=/hadoop/dfs/data
            - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
        ports:
            - 9864:9864
        volumes:
            - hadoop-datanode:/hadoop/dfs/data

    resourcemanager:
        build:
            context: ./hadoop/resourcemanager
            dockerfile: Dockerfile
        image: ionicastefan20/hadoop-resourcemanager:3.3.6
        container_name: resourcemanager
        hostname: resourcemanager
        depends_on:
            - namenode
        environment:
            - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
        ports:
            - 8088:8088

    nodemanager:
        build:
            context: ./hadoop/nodemanager
            dockerfile: Dockerfile
        image: ionicastefan20/hadoop-nodemanager:3.3.6
        container_name: nodemanager
        hostname: nodemanager
        depends_on:
            - resourcemanager
        environment:
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
            - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager

    historyserver:
        build:
            context: ./hadoop/historyserver
            dockerfile: Dockerfile
        image: ionicastefan20/hadoop-historyserver:3.3.6
        container_name: historyserver
        hostname: historyserver
        depends_on:
            - namenode
            - datanode
            - resourcemanager
            - nodemanager
        environment:
            - CORE_CONF_fs_defaultFS=hdfs://namenode:9000
            - HDFS_CONF_dfs_namenode_datanode_registration_ip___hostname___check=false
            - YARN_CONF_yarn_resourcemanager_hostname=resourcemanager
        volumes:
            - hadoop-historyserver:/hadoop/yarn/timeline
        ports:
            - 8188:8188

    spark-master:
        build:
            context: .
            dockerfile: spark.Dockerfile
        image: ionicastefan20/spark:3.5.1
        container_name: spark-master
        hostname: spark-master
        depends_on:
            - namenode
            - datanode
        environment:
            - SPARK_MODE=master
        ports:
            - 8080:8080
            - 7077:7077
        volumes:
            - ./core-site.xml:/opt/bitnami/spark/conf/core-site.xml
            - ./hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml
            - ./data/spark:/spark_data

    spark-worker-1:
        image: ionicastefan20/spark:3.5.1
        container_name: spark-worker-1
        hostname: spark-worker-1
        depends_on:
            - spark-master
        environment:
            - SPARK_MODE=worker
            - SPARK_WORKER_CORES=2
            - SPARK_WORKER_MEMORY=2g
            - SPARK_MASTER_URL=spark://spark-master:7077
        ports:
            - 8081:8081
        volumes:
            - ./core-site.xml:/opt/bitnami/spark/conf/core-site.xml
            - ./hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml

    spark-worker-2:
        image: ionicastefan20/spark:3.5.1
        container_name: spark-worker-2
        hostname: spark-worker-2
        depends_on:
            - spark-master
        environment:
            - SPARK_MODE=worker
            - SPARK_WORKER_CORES=2
            - SPARK_WORKER_MEMORY=2g
            - SPARK_MASTER_URL=spark://spark-master:7077
        ports:
            - 8082:8081
        volumes:
            - ./core-site.xml:/opt/bitnami/spark/conf/core-site.xml
            - ./hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml

    spark-worker-3:
        image: ionicastefan20/spark:3.5.1
        container_name: spark-worker-3
        hostname: spark-worker-3
        depends_on:
            - spark-master
        environment:
            - SPARK_MODE=worker
            - SPARK_WORKER_CORES=2
            - SPARK_WORKER_MEMORY=2g
            - SPARK_MASTER_URL=spark://spark-master:7077
        ports:
            - 8083:8081
        volumes:
            - ./core-site.xml:/opt/bitnami/spark/conf/core-site.xml
            - ./hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml

    spark-worker-4:
        image: ionicastefan20/spark:3.5.1
        container_name: spark-worker-4
        hostname: spark-worker-4
        depends_on:
            - spark-master
        environment:
            - SPARK_MODE=worker
            - SPARK_WORKER_CORES=2
            - SPARK_WORKER_MEMORY=2g
            - SPARK_MASTER_URL=spark://spark-master:7077
        ports:
            - 8084:8081
        volumes:
            - ./core-site.xml:/opt/bitnami/spark/conf/core-site.xml
            - ./hdfs-site.xml:/opt/bitnami/spark/conf/hdfs-site.xml

volumes:
    hadoop-namenode:
    hadoop-datanode:
    hadoop-historyserver:
